{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d630849",
   "metadata": {},
   "source": [
    "# This project is contributed by Yanfeng, Garvit and Hyosang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d326191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import surprise\n",
    "from surprise.prediction_algorithms.knns import KNNWithMeans\n",
    "from surprise.model_selection import cross_validate, KFold, train_test_split\n",
    "from tqdm import tqdm\n",
    "from surprise.accuracy import rmse\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from surprise.prediction_algorithms.matrix_factorization import NMF, SVD\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117e476",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 1A ########################\n",
    "rating_file_name = \"ratings.csv\"\n",
    "dataset = pd.read_csv(rating_file_name)\n",
    "print(dataset.info)\n",
    "num_available_rating = dataset['rating'].shape[0]\n",
    "print('num_available_rating:', num_available_rating)\n",
    "# construct the Rating matrix R through the pivot table\n",
    "R = pd.pivot_table(data=dataset, index='userId', columns='movieId', values='rating', fill_value=0)\n",
    "print(R)\n",
    "num_possible_rating = R.size\n",
    "print(R.size)\n",
    "sparsity = num_available_rating / num_possible_rating\n",
    "print('sparsity=', sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9704cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 1B ########################\n",
    "plt.hist(dataset['rating'], bins=np.arange(0, 6, 0.5)-0.25, rwidth=0.5)\n",
    "plt.title('Frequency of the Rating Values')\n",
    "plt.xlabel('Rating Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(np.arange(0, 5.5, 0.5))\n",
    "plt.savefig('Q1b.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 1C ########################\n",
    "num_rating_per_movie = []\n",
    "n = 0\n",
    "R_mat = R.values\n",
    "for i in range(R.shape[1]):\n",
    "    for j in range(R.shape[0]):\n",
    "        if R_mat[j, i] != 0:\n",
    "            n = n + 1\n",
    "    num_rating_per_movie.append(n)\n",
    "    n = 0\n",
    "movieID = R.columns.values\n",
    "new_mat = np.vstack((movieID, np.array(num_rating_per_movie)))\n",
    "index = new_mat[1, :].argsort()[::-1]\n",
    "new_mat = new_mat[:, index]\n",
    "print(new_mat)\n",
    "movieID_new = [str(x) for x in new_mat[0, :]]\n",
    "plt.plot(movieID_new[:20], new_mat[1, :20])\n",
    "plt.xlabel('Movie ID')\n",
    "plt.xticks(fontsize=6)\n",
    "plt.ylabel('Frequency of Ratings')\n",
    "plt.title('Distribution of the number of ratings received among movies (Portion)')\n",
    "plt.savefig('Q1c1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# to observe the rating frequency of every movie, but do not print the movieId on X-axis. \n",
    "plt.plot(np.arange(R.shape[1]), new_mat[1, :])\n",
    "plt.ylabel('Frequency of Ratings')\n",
    "plt.savefig('Q1c2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 1D ########################\n",
    "num_rating_per_user = []\n",
    "n = 0\n",
    "R_mat = R.values\n",
    "for i in range(R.shape[0]):\n",
    "    for j in range(R.shape[1]):\n",
    "        if R_mat[i, j] != 0:\n",
    "            n = n + 1\n",
    "    num_rating_per_user.append(n)\n",
    "    n = 0\n",
    "userID = R.index.values.reshape(1, -1)\n",
    "new_mat = np.vstack((userID, np.array(num_rating_per_user)))\n",
    "index = new_mat[1, :].argsort()[::-1]\n",
    "new_mat = new_mat[:, index]\n",
    "print(new_mat)\n",
    "userID_new = [str(x) for x in new_mat[0, :]]\n",
    "plt.plot(userID_new[:20], new_mat[1, :20])\n",
    "plt.xlabel('User ID')\n",
    "plt.xticks(fontsize=6)\n",
    "plt.ylabel('Frequency of Ratings')\n",
    "plt.title('Distribution of the number of ratings among users (Portion)')\n",
    "plt.savefig('Q1d1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# to observe the rating frequency of every user, but do not print the userId on X-axis.\n",
    "plt.plot(np.arange(R.shape[0]), new_mat[1, :])\n",
    "plt.ylabel('Frequency of Ratings')\n",
    "plt.savefig('Q1d2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 1F ########################\n",
    "variance = []\n",
    "for i in range(R.shape[1]):\n",
    "    k = R_mat[:, i].reshape(-1)\n",
    "    var = np.var(R_mat[:, i][R_mat[:, i] > 0])\n",
    "    variance.append(var)\n",
    "\n",
    "plt.hist(variance, bins=np.arange(0, max(variance)+1, 0.5)-0.25, rwidth=0.5)\n",
    "plt.title('Frequency of the Rating Variance of movies')\n",
    "plt.xlabel('Rating Variance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(np.arange(0, 5.5, 0.5))\n",
    "plt.savefig('Q1f.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29666121",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 4 ########################\n",
    "dataset_sup = surprise.Dataset.load_from_df(dataset[['userId', 'movieId', 'rating']],\n",
    "                                            reader=surprise.Reader(rating_scale=(0.5, 5), skip_lines=0))\n",
    "print(dataset_sup)\n",
    "k_neighbors = np.arange(2, 102, 2)\n",
    "rmse_ave = []\n",
    "mae_ave = []\n",
    "for i in tqdm(range(2, 102, 2)):\n",
    "    knn = KNNWithMeans(k=i, min_k=1, sim_options={'name': 'pearson'}, verbose=False)\n",
    "    scores = cross_validate(algo=knn, data=dataset_sup, measures=['rmse', 'mae'], cv=10, n_jobs=-1, verbose=False)\n",
    "    rmse_average = np.mean(scores['test_rmse'])\n",
    "    rmse_ave.append(rmse_average)\n",
    "    mae_average = np.mean(scores['test_mae'])\n",
    "    mae_ave.append(mae_average)\n",
    "\n",
    "plt.plot(k_neighbors, rmse_ave)\n",
    "plt.ylabel('Average RMSE')\n",
    "plt.xlabel('k')\n",
    "plt.savefig('Q4_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(k_neighbors, mae_ave)\n",
    "plt.ylabel('Average MAE')\n",
    "plt.xlabel('k')\n",
    "plt.savefig('Q4_mae.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838042b6",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 5 ########################\n",
    "rmse_diff = np.diff(rmse_ave)  # compute rmse_ave[n+1]-rmse_ave[n] which can help your eyeball!\n",
    "mae_diff = np.diff(mae_ave)\n",
    "k_neighbors_diff = np.arange(2, 100, 2)\n",
    "\n",
    "plt.plot(k_neighbors_diff, rmse_diff)\n",
    "plt.ylabel('RMSE Diffence')\n",
    "plt.xlabel('k')\n",
    "plt.savefig('Q5_rmse_diffence.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(k_neighbors_diff, mae_diff)\n",
    "plt.ylabel('MAE Diffence')\n",
    "plt.xlabel('k')\n",
    "plt.savefig('Q5_mae_diffence.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac4934",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 6 ########################\n",
    "dataset_original = dataset.copy()  # the original dataset without trimming\n",
    "\n",
    "num_rating_per_movie = []\n",
    "n = 0\n",
    "R_mat = R.values\n",
    "for i in range(R.shape[1]):\n",
    "    for j in range(R.shape[0]):\n",
    "        if R_mat[j, i] != 0:\n",
    "            n = n + 1\n",
    "    num_rating_per_movie.append(n)\n",
    "    n = 0\n",
    "movieID = R.columns.values\n",
    "new_mat = np.vstack((movieID, np.array(num_rating_per_movie)))\n",
    "# print(new_mat)\n",
    "variance = []\n",
    "for i in range(R.shape[1]):\n",
    "    k = R_mat[:, i].reshape(-1)\n",
    "    var = np.var(R_mat[:, i][R_mat[:, i] > 0])\n",
    "    variance.append(var)\n",
    "new_var_mat = np.vstack((new_mat, np.array(variance)))  \n",
    "# new_var_mat: first row: movie ID; second row: number of ratings of each movie; third row: variance of rating of each movie\n",
    "print(new_var_mat)\n",
    "\n",
    "def trimming(var_mat, dataset, option='popular'):  # trim the dataset (pd.dataframe format)\n",
    "    dataset1 = dataset.copy()  \n",
    "    # it is necessary to copy pd.dataframe if you want to revise the data! Otherwise, the original data will change.\n",
    "    if option == 'popular':\n",
    "        mat = var_mat[0, :][var_mat[1, :] > 2]  # choose the ID of popular movie\n",
    "        # print(mat)\n",
    "        delete_index = []\n",
    "        for i in range(dataset1['rating'].shape[0]):\n",
    "            if dataset1['movieId'][i] not in mat:\n",
    "                delete_index.append(i)\n",
    "        dataset1.drop(delete_index, inplace=True)\n",
    "    elif option == 'unpopular':\n",
    "        mat = var_mat[0, :][var_mat[1, :] <= 2]\n",
    "        delete_index = []\n",
    "        for i in range(dataset1['rating'].shape[0]):\n",
    "            if dataset1['movieId'][i] not in mat:\n",
    "                delete_index.append(i)\n",
    "        dataset1.drop(delete_index, inplace=True)\n",
    "    elif option == 'high_variance':\n",
    "        mat = var_mat[:2, :][:, var_mat[2, :] >= 2]  # variance >= 2\n",
    "        # print(mat)\n",
    "        mat = mat[0, :][mat[1, :] >= 5]\n",
    "        delete_index = []\n",
    "        for i in range(dataset1['rating'].shape[0]):\n",
    "            if dataset1['movieId'][i] not in mat:\n",
    "                delete_index.append(i)\n",
    "        dataset1.drop(delete_index, inplace=True)\n",
    "            \n",
    "    return dataset1.reset_index(drop=True)\n",
    "\n",
    "\n",
    "dataset_popular = trimming(new_var_mat, dataset_original, option='popular')\n",
    "print(dataset_popular)\n",
    "dataset_unpopular = trimming(new_var_mat, dataset_original, option='unpopular')\n",
    "print(dataset_unpopular)\n",
    "dataset_high_variance = trimming(new_var_mat, dataset_original, option='high_variance')\n",
    "print(dataset_high_variance)\n",
    "print(dataset_original)\n",
    "\n",
    "# Note: Use the following Superise-format dataset when you call the models in Surprise\n",
    "# dataset_sup_original: Superise-format dataset without trimming\n",
    "dataset_sup_original = surprise.Dataset.load_from_df(dataset_original[['userId', 'movieId', 'rating']],\n",
    "                                                     reader=surprise.Reader(rating_scale=(0.5, 5), skip_lines=0))\n",
    "# dataset_sup_popular: Superise-format dataset with Popular movie trimming\n",
    "dataset_sup_popular = surprise.Dataset.load_from_df(dataset_popular[['userId', 'movieId', 'rating']],\n",
    "                                                     reader=surprise.Reader(rating_scale=(0.5, 5), skip_lines=0))\n",
    "# dataset_sup_unpopular: Superise-format dataset with UnPopular movie trimming\n",
    "dataset_sup_unpopular = surprise.Dataset.load_from_df(dataset_unpopular[['userId', 'movieId', 'rating']],\n",
    "                                                     reader=surprise.Reader(rating_scale=(0.5, 5), skip_lines=0))\n",
    "# dataset_sup_high_variance: Superise-format dataset with High variance movie trimming\n",
    "dataset_sup_high_variance = surprise.Dataset.load_from_df(dataset_high_variance[['userId', 'movieId', 'rating']],\n",
    "                                                     reader=surprise.Reader(rating_scale=(0.5, 5), skip_lines=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c16e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular movie trimming, KNN\n",
    "# Note: It will cost about 10 minutes to run the codes in this cell\n",
    "k_neighbors = np.arange(2, 102, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 102, 2)):\n",
    "    knn = KNNWithMeans(k=i, min_k=1, sim_options={'name': 'pearson'}, verbose=False)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_popular):  # do the 10-fold split\n",
    "        popular_rating_predict = knn.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=popular_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within Popular Movies')\n",
    "plt.xlabel('k')\n",
    "plt.savefig('Q6_popular_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])  # best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpopular movie trimming, KNN\n",
    "k_neighbors = np.arange(2, 102, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 102, 2)):\n",
    "    knn = KNNWithMeans(k=i, min_k=1, sim_options={'name': 'pearson'}, verbose=False)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_unpopular):\n",
    "        unpopular_rating_predict = knn.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=unpopular_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within Unpopular Movies')\n",
    "plt.xlabel('k')\n",
    "plt.savefig('Q6_unpopular_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])  # best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High_variance movie trimming, KNN\n",
    "k_neighbors = np.arange(2, 102, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 102, 2)):\n",
    "    knn = KNNWithMeans(k=i, min_k=1, sim_options={'name': 'pearson'}, verbose=False)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_high_variance):\n",
    "        high_variance_rating_predict = knn.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=high_variance_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within High Variance Movies')\n",
    "plt.xlabel('k')\n",
    "plt.savefig('Q6_high_variance_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])  # best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(userID, movieID):\n",
    "    # get the origial rating in the test set by searching in the original R_mat\n",
    "    # not used\n",
    "    return float(np.squeeze(R_mat[np.where(R.index.values == userID), np.where(R.columns.values == movieID)]))\n",
    "\n",
    "def draw_roc_curve(fpr, tpr, model_name):\n",
    "    # not used\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "    plt.title(model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61737974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of popular movies, KNN\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_popular)\n",
    "# print(dataset_popular_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_popular, test_size=0.1, random_state=42)        \n",
    "knn = KNNWithMeans(k=46, min_k=1, sim_options={'name': 'pearson'}, verbose=False) # Note: k should be the best k in terms of RMSE\n",
    "predict = knn.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)\n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of popular trimming (KNN)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q6_popular_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of unpopular movies, KNN\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_unpopular)\n",
    "# print(dataset_unpopular_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_unpopular, test_size=0.1, random_state=42)\n",
    "knn = KNNWithMeans(k=2, min_k=1, sim_options={'name': 'pearson'}, verbose=False)  # Note: k should be the best k in terms of RMSE\n",
    "predict = knn.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)\n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of unpopular trimming (KNN)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q6_unpopular_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of high variance movies, KNN\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_high_variance)\n",
    "# print(dataset_high_variance_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_high_variance, test_size=0.1, random_state=42)\n",
    "knn = KNNWithMeans(k=2, min_k=1, sim_options={'name': 'pearson'}, verbose=False)  # Note: k should be the best k in terms of RMSE\n",
    "predict = knn.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "        if validset[i][2] < threshold:\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)    \n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of high variance trimming (KNN)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q6_high_variance_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of original movies, KNN\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_original)\n",
    "# print(dataset_original_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_original, test_size=0.1, random_state=42)\n",
    "knn = KNNWithMeans(k=30, min_k=1, sim_options={'name': 'pearson'}, verbose=False)  # k is the eyeball minimum k in Q5\n",
    "predict = knn.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)   \n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds without trimming (KNN)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q6_original_ROC.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# save threshold = 3.0 values for ROC comparison\n",
    "knn_fpr = fpr_4[1]\n",
    "knn_tpr = tpr_4[1]\n",
    "knn_auc = auc_4[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c43bb0d",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 8A ########################\n",
    "# It is similar to Question 4\n",
    "print(dataset_sup_original)\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "rmse_ave = []\n",
    "mae_ave = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    nmf = NMF(n_factors=i, n_epochs=50, random_state=42)\n",
    "    scores = cross_validate(algo=nmf, data=dataset_sup_original, measures=['rmse', 'mae'], cv=10, n_jobs=-1, verbose=False)\n",
    "    rmse_average = np.mean(scores['test_rmse'])\n",
    "    rmse_ave.append(rmse_average)\n",
    "    mae_average = np.mean(scores['test_mae'])\n",
    "    mae_ave.append(mae_average)\n",
    "\n",
    "plt.plot(k_neighbors, rmse_ave)\n",
    "plt.ylabel('Average RMSE')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q8A_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(k_neighbors, mae_ave)\n",
    "plt.ylabel('Average MAE')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q8A_mae.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb66504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 8B ########################\n",
    "# Note: the minimum RMSE/MAE index may vary when re-run the cell above, but the results are similar (around 16-22)\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "min_rmse_ave = min(rmse_ave)\n",
    "min_rmse_ave_index = rmse_ave.index(min_rmse_ave)\n",
    "print('Min average RMSE:', min_rmse_ave)\n",
    "print('Min average RMSE index:', min_rmse_ave_index)\n",
    "print('Num of latent factors of Min average RMSE:', k_neighbors[min_rmse_ave_index])\n",
    "\n",
    "min_mae_ave = min(mae_ave)\n",
    "min_mae_ave_index = mae_ave.index(min_mae_ave)\n",
    "print('Min average MAE:', min_mae_ave)\n",
    "print('Min average MAE index:', min_mae_ave_index)\n",
    "print('Num of latent factors of Min average MAE:', k_neighbors[min_mae_ave_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 8C ########################\n",
    "# Popular movie trimming, NMF\n",
    "# Note: It will cost about 10 minutes to run the codes in this cell\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    nmf = NMF(n_factors=i, n_epochs=50, random_state=42)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_popular):\n",
    "        popular_rating_predict = nmf.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=popular_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within Popular Movies')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q8C_popular_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpopular movie trimming, NMF\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    nmf = NMF(n_factors=i, n_epochs=50, random_state=42)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_unpopular):\n",
    "        unpopular_rating_predict = nmf.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=unpopular_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within Unpopular Movies')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q8C_unpopular_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b23aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High_variance movie trimming, NMF\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    nmf = NMF(n_factors=i, n_epochs=50, random_state=42)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_high_variance):\n",
    "        high_variance_rating_predict = nmf.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=high_variance_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within High Variance Movies')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q8C_high_variance_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of popular movies, NMF\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_popular)\n",
    "# print(dataset_popular_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_popular, test_size=0.1, random_state=42)        \n",
    "nmf = NMF(n_factors=16, n_epochs=50, random_state=42) # Note: n_factors should be the best k in terms of RMSE\n",
    "predict = nmf.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)\n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of popular trimming (NMF)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q8_popular_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e035fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of unpopular movies, NMF\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_unpopular)\n",
    "# print(dataset_unpopular_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_unpopular, test_size=0.1, random_state=42)\n",
    "nmf = NMF(n_factors=50, n_epochs=50, random_state=42) # Note: n_factors should be the best k in terms of RMSE\n",
    "predict = nmf.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)\n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of unpopular trimming (NMF)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q8_unpopular_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of high variance movies, NMF\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_high_variance)\n",
    "# print(dataset_high_variance_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_high_variance, test_size=0.1, random_state=42)\n",
    "nmf = NMF(n_factors=50, n_epochs=50, random_state=42) # Note: n_factors should be the best k in terms of RMSE\n",
    "predict = nmf.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)    \n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of high variance trimming (NMF)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q8_high_variance_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47aa691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of original movies, NMF\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_original)\n",
    "# print(dataset_original_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_original, test_size=0.1, random_state=42)\n",
    "nmf = NMF(n_factors=18, n_epochs=50, random_state=42) # Note: n_factors should be the best k in terms of RMSE/MAE\n",
    "predict = nmf.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)   \n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds without trimming (NMF)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q8_original_ROC.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# save threshold = 3.0 values for ROC comparison\n",
    "nmf_fpr = fpr_4[1]\n",
    "nmf_tpr = tpr_4[1]\n",
    "nmf_auc = auc_4[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125ad69",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 9 ########################\n",
    "# retrain nmf here by setting n_factors=20\n",
    "trainset, validset = train_test_split(dataset_sup_original, test_size=0.1, random_state=42)\n",
    "nmf = NMF(n_factors=20, n_epochs=50, random_state=42)\n",
    "predict = nmf.fit(trainset).test(validset)\n",
    "U = nmf.pu\n",
    "V = nmf.qi\n",
    "print('U:', U)\n",
    "print(U.shape)\n",
    "print('V:', V)\n",
    "print(V.shape)  # why # of rows of V is not identical to # of movies? because some unpopular movies are not in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62465cc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_index = []\n",
    "for i in range(V.shape[1]):\n",
    "    idx = np.argsort(-V[:,i])  # descending order\n",
    "    sorted_index.append(idx[0:10])\n",
    "print(sorted_index)\n",
    "genres_file_name = \"movies.csv\"\n",
    "generes_dataset = pd.read_csv(genres_file_name)    \n",
    "print(generes_dataset.info)\n",
    "for i in range(len(sorted_index)):\n",
    "    print('Column=', i)\n",
    "    print(generes_dataset['genres'][sorted_index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c5a64",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 10A ########################\n",
    "# It is similar to Question 4\n",
    "print(dataset_sup_original)\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "rmse_ave = []\n",
    "mae_ave = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    svd = SVD(n_factors=i, random_state=42, verbose=False)\n",
    "    scores = cross_validate(algo=svd, data=dataset_sup_original, measures=['rmse', 'mae'], cv=10, n_jobs=-1, verbose=False)\n",
    "    rmse_average = np.mean(scores['test_rmse'])\n",
    "    rmse_ave.append(rmse_average)\n",
    "    mae_average = np.mean(scores['test_mae'])\n",
    "    mae_ave.append(mae_average)\n",
    "\n",
    "plt.plot(k_neighbors, rmse_ave)\n",
    "plt.ylabel('Average RMSE')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q10A_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(k_neighbors, mae_ave)\n",
    "plt.ylabel('Average MAE')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q10A_mae.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531bb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 10B ########################\n",
    "# Note: the minimum RMSE/MAE index may vary when re-run the cell above, but the results are similar (around 16-22)\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "min_rmse_ave = min(rmse_ave)\n",
    "min_rmse_ave_index = rmse_ave.index(min_rmse_ave)\n",
    "print('Min average RMSE:', min_rmse_ave)\n",
    "print('Min average RMSE index:', min_rmse_ave_index)\n",
    "print('Num of latent factors of Min average RMSE:', k_neighbors[min_rmse_ave_index])\n",
    "k_original = k_neighbors[min_rmse_ave_index]\n",
    "\n",
    "min_mae_ave = min(mae_ave)\n",
    "min_mae_ave_index = mae_ave.index(min_mae_ave)\n",
    "print('Min average MAE:', min_mae_ave)\n",
    "print('Min average MAE index:', min_mae_ave_index)\n",
    "print('Num of latent factors of Min average MAE:', k_neighbors[min_mae_ave_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7be355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 10C ########################\n",
    "# Popular movie trimming, SVD\n",
    "# Note: It will cost about 10 minutes to run the codes in this cell\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    svd = SVD(n_factors=i, random_state=42)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_popular):\n",
    "        popular_rating_predict = svd.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=popular_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within Popular Movies')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q10C_popular_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])\n",
    "k_popular = k_neighbors[min_rmse_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpopular movie trimming, SVD\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    svd = SVD(n_factors=i, random_state=42)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_unpopular):\n",
    "        unpopular_rating_predict = svd.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=unpopular_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within Unpopular Movies')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q10C_unpopular_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])\n",
    "k_unpopular = k_neighbors[min_rmse_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d698b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High_variance movie trimming, SVD\n",
    "k_neighbors = np.arange(2, 52, 2)\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "rmse_scores = []\n",
    "for i in tqdm(range(2, 52, 2)):\n",
    "    svd = SVD(n_factors=i, random_state=42)\n",
    "    rmse_fold = []\n",
    "    for trainset, testset in kf.split(dataset_sup_high_variance):\n",
    "        high_variance_rating_predict = svd.fit(trainset).test(testset)\n",
    "        score = rmse(predictions=high_variance_rating_predict, verbose=False)\n",
    "        rmse_fold.append(score)\n",
    "    rmse_scores.append(np.mean(rmse_fold))\n",
    "plt.plot(k_neighbors, rmse_scores)\n",
    "plt.ylabel('Average RMSE within High Variance Movies')\n",
    "plt.xlabel('Number of latent factors')\n",
    "plt.savefig('Q10C_high_variance_rmse.png', dpi=300)\n",
    "plt.show()\n",
    "min_rmse = min(rmse_scores)\n",
    "min_rmse_index = rmse_scores.index(min_rmse)\n",
    "print(min_rmse)\n",
    "print(min_rmse_index)\n",
    "print(k_neighbors[min_rmse_index])\n",
    "k_high_var = k_neighbors[min_rmse_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1309614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of popular movies, SVD\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_popular)\n",
    "# print(dataset_popular_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_popular, test_size=0.1, random_state=42)        \n",
    "svd = SVD(n_factors=k_popular, random_state=42) # Note: n_factors should be the best k in terms of RMSE\n",
    "predict = svd.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)\n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of popular trimming (SVD)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q10_popular_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of unpopular movies, SVD\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_unpopular)\n",
    "# print(dataset_unpopular_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_unpopular, test_size=0.1, random_state=42)\n",
    "svd = SVD(n_factors=k_unpopular, random_state=42) # Note: n_factors should be the best k in terms of RMSE\n",
    "predict = svd.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)\n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of unpopular trimming (SVD)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q10_unpopular_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of high variance movies, SVD\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_high_variance)\n",
    "# print(dataset_high_variance_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_high_variance, test_size=0.1, random_state=42)\n",
    "svd = SVD(n_factors=k_high_var, random_state=42) # Note: n_factors should be the best k in terms of RMSE\n",
    "predict = svd.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)    \n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds of high variance trimming (SVD)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q10_high_variance_ROC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC of original movies, SVD\n",
    "rating_thresholds = [2.5, 3, 3.5, 4]\n",
    "fpr_4 = []\n",
    "tpr_4 = []\n",
    "hold_4 = []\n",
    "auc_4 = []\n",
    "\n",
    "# print(dataset_original)\n",
    "# print(dataset_original_threshold)\n",
    "\n",
    "trainset, validset = train_test_split(dataset_sup_original, test_size=0.1, random_state=42)\n",
    "svd = SVD(n_factors=k_original, random_state=42) # Note: n_factors should be the best k in terms of RMSE/MAE\n",
    "predict = svd.fit(trainset).test(validset)\n",
    "for thres in rating_thresholds:\n",
    "    real_rating = []\n",
    "    predict_rating = []\n",
    "    threshold = thres\n",
    "    for i in range(len(predict)):\n",
    "        if validset[i][2] < threshold:  # apply the rating threshold (such as 2.5, 3.0) on y_true in validset\n",
    "            real_rating.append(0.0)\n",
    "        else:\n",
    "            real_rating.append(1.0)   \n",
    "        predict_rating.append(predict[i].est)\n",
    "    fpr, tpr, hold = roc_curve(real_rating, predict_rating)\n",
    "    fpr_4.append(fpr)\n",
    "    tpr_4.append(tpr)\n",
    "    hold_4.append(hold)\n",
    "    auc = roc_auc_score(real_rating, predict_rating)\n",
    "    auc_4.append(auc)\n",
    "    \n",
    "print('AUC for four thresholds:', auc_4)\n",
    "for i in range(4):\n",
    "    plt.plot(fpr_4[i], tpr_4[i], label='threshold='+str(rating_thresholds[i]))\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for four thresholds without trimming (SVD)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Q10_original_ROC.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# save threshold = 3.0 values for ROC comparison\n",
    "mf_fpr = fpr_4[1]\n",
    "mf_tpr = tpr_4[1]\n",
    "mf_auc = auc_4[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d305c",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase\n",
    "\n",
    "# Define naive collaborative filter class that estimates using mean ratings\n",
    "class Naive(AlgoBase):\n",
    "    def __init__(self):\n",
    "        AlgoBase.__init__(self)\n",
    "\n",
    "    def estimate(self, uid, iid):\n",
    "        return np.mean([r for (_, r) in self.trainset.ur[uid]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "naive = Naive()\n",
    "score = cross_validate(algo=naive, data=dataset_sup_original, measures=['rmse'], cv=10, verbose=False)\n",
    "print(\"Average RMSE for naive collaborative filter:\", np.mean(score['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05871f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular movie trimming, Naive\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "\n",
    "naive = Naive()\n",
    "rmse_fold = []\n",
    "for trainset, testset in kf.split(dataset_sup_popular):\n",
    "    popular_rating_predict = naive.fit(trainset).test(testset)\n",
    "    score = rmse(predictions=popular_rating_predict, verbose=False)\n",
    "    rmse_fold.append(score)\n",
    "print(\"Average RMSE for Popular Movies:\", np.mean(rmse_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cece0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpopular movie trimming, Naive\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "\n",
    "naive = Naive()\n",
    "rmse_fold = []\n",
    "for trainset, testset in kf.split(dataset_sup_unpopular):\n",
    "    unpopular_rating_predict = naive.fit(trainset).test(testset)\n",
    "    score = rmse(predictions=unpopular_rating_predict, verbose=False)\n",
    "    rmse_fold.append(score)\n",
    "print(\"Average RMSE for Unpopular Movies:\", np.mean(rmse_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High variance movie trimming, Naive\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42)\n",
    "\n",
    "naive = Naive()\n",
    "rmse_fold = []\n",
    "for trainset, testset in kf.split(dataset_sup_high_variance):\n",
    "    high_variance_rating_predict = naive.fit(trainset).test(testset)\n",
    "    score = rmse(predictions=high_variance_rating_predict, verbose=False)\n",
    "    rmse_fold.append(score)\n",
    "print(\"Average RMSE for High Variance Movies:\", np.mean(rmse_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f21d4",
   "metadata": {},
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b56944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot comparison of ROC curves for three architectures\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(knn_fpr, knn_tpr, '-', label='k-NN')\n",
    "plt.plot(nmf_fpr, nmf_tpr, '--', label='NMF')\n",
    "plt.plot(mf_fpr, mf_tpr, '-.', label='MF')\n",
    "\n",
    "plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "plt.title('ROC curve for three models without trimming')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e8232",
   "metadata": {},
   "source": [
    "## Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd21043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_fetch_validation_set(validset, t):\n",
    "    # save information about each user to validate two conditions\n",
    "    # also get G for later parts of the project\n",
    "    user_information = {}\n",
    "\n",
    "    # go through each user in the validation set\n",
    "    for uid, iid, rating in validset:\n",
    "        # first time seeing this user id\n",
    "        if uid not in user_information:\n",
    "            user_information[uid] = [0, set()]\n",
    "        \n",
    "        # update item count\n",
    "        user_information[uid][0] += 1\n",
    "        \n",
    "        # add movie id to set if user has liked the movie\n",
    "        if rating >= 3.0:\n",
    "            user_information[uid][1].add(iid)\n",
    "    \n",
    "    # do a second pass through the dataset and use prior information to\n",
    "    # remove or keep entries\n",
    "    # the first condition - ensures that S(t) is valid with t elements\n",
    "    # the second condition - ensures that user has liked a movie\n",
    "    validset = [entry for entry in validset if user_information[entry[0]][0] >= t and len(user_information[entry[0]][1]) > 0]\n",
    "    return validset, user_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee01978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def calculate_precision_and_recall(predictions, t, user_information):\n",
    "    # G = set of liked items by user id = second entry in user_information dict\n",
    "    # create a set of estimated ratings per user - to be sorted for top t elements\n",
    "    estimated_ratings_for_user = {}\n",
    "    for uid, iid, _, estimate, _ in predictions:\n",
    "        if uid not in estimated_ratings_for_user:\n",
    "            estimated_ratings_for_user[uid] = set()\n",
    "        \n",
    "        # save estimated rating and movie ID\n",
    "        estimated_ratings_for_user[uid].add((iid, estimate))\n",
    "\n",
    "    precision_per_user = []\n",
    "    recall_per_user = []\n",
    "    # go through all users and calculate precision and recall\n",
    "    for uid, movie_and_estimates in estimated_ratings_for_user.items():\n",
    "        # top t movie ids based on estimates (descending order)\n",
    "        sorted_t_movie_and_estimates = sorted(movie_and_estimates, key = itemgetter(1), reverse = True)[:t]\n",
    "        # get a set of movies S(t) to compare to G\n",
    "        St = set([movie_and_estimate[0] for movie_and_estimate in sorted_t_movie_and_estimates])\n",
    "        # calculate intersection with liked movies G\n",
    "        intersection = St.intersection(user_information[uid][1])\n",
    "        # calculate precision and recall for user\n",
    "        precision_per_user.append(len(intersection)/len(St))\n",
    "        recall_per_user.append(len(intersection)/len(user_information[uid][1]))\n",
    "    \n",
    "    # return average precision and recall for all users\n",
    "    return np.mean(precision_per_user), np.mean(recall_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ba9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pr_metrics(model, dataset):\n",
    "    # 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, random_state=42)\n",
    "    # sweep t from 1 to 25 (inclusive) in step sizes of 1\n",
    "    precision_per_t = []\n",
    "    recall_per_t = []\n",
    "\n",
    "    for t in tqdm(range(1, 26)):\n",
    "        precision_per_fold = []\n",
    "        recall_per_fold = []\n",
    "\n",
    "        # split dataset\n",
    "        for trainset, validset in kf.split(dataset):\n",
    "            # get cleaned validation set and user information\n",
    "            validset, user_information = clean_and_fetch_validation_set(validset, t)\n",
    "            # get predictions\n",
    "            predictions = model.fit(trainset).test(validset)\n",
    "            # get precision and recall\n",
    "            precision, recall = calculate_precision_and_recall(predictions, t, user_information)\n",
    "            # append to per fold values\n",
    "            precision_per_fold.append(precision)\n",
    "            recall_per_fold.append(recall)\n",
    "        \n",
    "        precision_per_t.append(np.mean(precision_per_fold))\n",
    "        recall_per_t.append(np.mean(recall_per_fold))\n",
    "    \n",
    "    return precision_per_t, recall_per_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 best models\n",
    "knn = KNNWithMeans(k=30, min_k=1, sim_options={'name': 'pearson'}, verbose=False)  # k is the eyeball minimum k in Q5\n",
    "nmf = NMF(n_factors=18, n_epochs=50, random_state=42) # Note: n_factors should be the best k in terms of RMSE/MAE\n",
    "svd = SVD(n_factors=k_original, random_state=42) # Note: n_factors should be the best k in terms of RMSE/MAE\n",
    "\n",
    "# compute precision and recall per t for each model\n",
    "knn_precision, knn_recall = compute_pr_metrics(knn, dataset_sup_original)\n",
    "nmf_precision, nmf_recall = compute_pr_metrics(nmf, dataset_sup_original)\n",
    "mf_precision, mf_recall = compute_pr_metrics(svd, dataset_sup_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9685f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(precision, recall, color, title):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.lineplot(x=recall, y=precision, color=color, marker='o')\n",
    "    plt.xlabel('Mean 10-fold recall')\n",
    "    plt.ylabel('Mean 10-fold precision')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# knn_precision, knn_recall\n",
    "def plot_against_t(data, ylabel, color, title):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.lineplot(x=range(1,26), y=data, color=color, marker='o')\n",
    "    plt.xlabel('Size of recommended list, t')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f474a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_t(knn_precision, \"Mean 10-fold precision\", \"tomato\", \"Precision of k-NN for varying size of recommended list t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5410152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_t(knn_recall, \"Mean 10-fold recall\", \"lightsalmon\", \"Recall of k-NN for varying size of recommended list t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(knn_precision, knn_recall, \"firebrick\", \"Precision-recall for k-NN with k = 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51418184",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_t(nmf_precision, \"Mean 10-fold precision\", \"darkturquoise\", \"Precision of NMF for varying size of recommended list t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_t(nmf_recall, \"Mean 10-fold recall\", \"lightskyblue\", \"Recall of NMF for varying size of recommended list t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085fb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(nmf_precision, nmf_recall, \"steelblue\", \"Precision-recall for NMF with factors = 18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cdb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_t(mf_precision, \"Mean 10-fold precision\", \"khaki\", \"Precision of MF for varying size of recommended list t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d70d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_t(mf_recall, \"Mean 10-fold recall\", \"wheat\", \"Recall of MF for varying size of recommended list t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd569eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(mf_precision, mf_recall, \"gold\", \"Precision-recall for MF with factors = \" + str(k_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09fbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot three precision-recall curves for three best architectures\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.lineplot(x=knn_recall, y=knn_precision, color='firebrick', marker='o', label='k-NN')\n",
    "plt.plot(nmf_recall, nmf_precision, color='steelblue', marker='o', label='NMF')\n",
    "plt.plot(mf_recall, mf_precision, color='gold', marker='o', label='MF')\n",
    "plt.legend()\n",
    "plt.xlabel('Mean 10-fold recall')\n",
    "plt.ylabel('Mean 10-fold precision')\n",
    "plt.title('Precision-recall curves for best architectures')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "39987ca6966f75618382f2ae5b08a4b2a561e189ea1b593602189bb0fc50e1ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

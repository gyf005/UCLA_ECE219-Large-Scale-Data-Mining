{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed13ccd0",
   "metadata": {},
   "source": [
    "# This project is contributed by Yanfeng Guo (UID:806073779),  Garvit Pugalia (UID: 504628127), Hyosang Ahn (UID: 606073544)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ba193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load main.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, recall_score, precision_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import umap.umap_ as umap\n",
    "import umap.plot\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad497199",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # make the training and testing samples the same as other groups\n",
    "random.seed(42)\n",
    "#################### Question 1 ########################\n",
    "# the diagrams are missing\n",
    "dataset = pd.read_csv('Project1-Classification.csv')\n",
    "print(dataset.shape)\n",
    "print(dataset.info)\n",
    "# the total number of alphanumeric characters per data point (row) in the feature full text\n",
    "num = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    num_alpha_numeric = len(re.findall(r\"\\w\", dataset['full_text'][i]))\n",
    "    # print(num_alpha_numeric)\n",
    "    num.append(num_alpha_numeric)\n",
    "plt.hist(num, bins=200)\n",
    "plt.title('The total number of alphanumeric characters per data point')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# The column leaf label – class on the x-axis\n",
    "plt.hist(dataset['leaf_label'], bins=9, rwidth=0.3)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.xlabel('Leaf label category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# The column root label – class on the x-axis\n",
    "plt.hist(dataset['root_label'])\n",
    "plt.xlabel('Root label category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 2 ########################\n",
    "train, test = train_test_split(dataset[[\"full_text\",\"root_label\",\"keywords\"]], test_size=0.2)\n",
    "print('train.shape:', train.shape)\n",
    "print('test.shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77eadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 3 ########################\n",
    "def clean(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    texter = re.sub('[\\d]', '', texter)  # by gyf, remove numbers\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter\n",
    "\n",
    "\n",
    "# train_clean_text = train['full_text'].apply(lambda x:clean(x))  # clean the text of each data point\n",
    "train = train.applymap(clean)  # clean the data of each data point in the training set\n",
    "test = test.applymap(clean)  # clean the data of each data point in the testing set\n",
    "train_clean_text = train['full_text']\n",
    "test_clean_text = test['full_text']\n",
    "print(train_clean_text)\n",
    "print('train_clean_text:', train_clean_text.shape)\n",
    "\n",
    "\n",
    "def get_pos(tag):  # get the property of a word from the pos_tag results\n",
    "    if tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)  # divide the words of each data point\n",
    "    tags = pos_tag(words)  # return the property of each word\n",
    "    lemma = []\n",
    "    for tag in tags:\n",
    "        pos = get_pos(tag[1])\n",
    "        lemma.append(wnl.lemmatize(tag[0], pos).lower())  # do the lemmatization\n",
    "    return ' '.join(lemma)\n",
    "\n",
    "\n",
    "train_lemmatized_text = train_clean_text.apply(lambda x:lemmatization(x))\n",
    "print(train_lemmatized_text)\n",
    "test_lemmatized_text = test_clean_text.apply(lambda x:lemmatization(x))\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', min_df=3)\n",
    "train_count = cv.fit_transform(train_lemmatized_text)  # use fit or fit_transform on the training set\n",
    "test_count = cv.transform(test_lemmatized_text)  # use transform on the testing set\n",
    "print(train_count)\n",
    "print(train_count.toarray())\n",
    "print(train_count.toarray().shape)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "train_tfidf = tfidf.fit_transform(train_count)\n",
    "test_tfidf = tfidf.transform(test_count)\n",
    "train_tfidf_mat = train_tfidf.toarray()\n",
    "print(train_tfidf_mat.shape)\n",
    "test_tfidf_mat = test_tfidf.toarray()\n",
    "print(test_tfidf_mat.shape)\n",
    "\n",
    "label_train_gt = []\n",
    "for i in train['root_label']:\n",
    "    if i == 'sports':\n",
    "        label_train_gt.append(1)\n",
    "    elif i == 'climate':\n",
    "        label_train_gt.append(0)\n",
    "\n",
    "label_test_gt = []\n",
    "for i in test['root_label']:\n",
    "    if i == 'sports':\n",
    "        label_test_gt.append(1)\n",
    "    elif i == 'climate':\n",
    "        label_test_gt.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 4 ########################\n",
    "k = [1, 10, 50, 100, 200, 500, 1000, 2000]\n",
    "ratio = []\n",
    "for i in k:\n",
    "    lsi = TruncatedSVD(i, random_state=0)\n",
    "    train_lsi_mat = lsi.fit_transform(train_tfidf_mat)  # fit model and perform dimensionality reduction\n",
    "    ratio.append(np.sum(lsi.explained_variance_ratio_))\n",
    "    print(np.sum(lsi.explained_variance_ratio_))\n",
    "plt.plot(k, ratio)\n",
    "plt.show()\n",
    "\n",
    "lsi = TruncatedSVD(50, random_state=0)  # random_state should not be changed, or the training data will change\n",
    "train_lsi_mat_50 = lsi.fit_transform(train_tfidf_mat)  # train_lsi_mat_50 = U_k @ Sigma_k;\n",
    "# train_lsi_mat_50: act as the training data of following sections\n",
    "VT = lsi.components_\n",
    "# print(train_tfidf_mat - train_lsi_mat_50 @ VT)\n",
    "lsi_fn = np.linalg.norm(train_tfidf_mat - train_lsi_mat_50 @ VT, 'fro')\n",
    "print('LSI MSE:', lsi_fn * lsi_fn)\n",
    "\n",
    "nmf = NMF(n_components=50, random_state=0)\n",
    "train_nmf_mat_50 = nmf.fit_transform(train_tfidf_mat)  # train_nmf_mat_50 = W\n",
    "H = nmf.components_\n",
    "nmf_fn = np.linalg.norm(train_tfidf_mat - train_nmf_mat_50 @ H, 'fro')\n",
    "print('NMF MSE:', nmf_fn * nmf_fn)\n",
    "\n",
    "test_lsi_mat_50 = lsi.transform(test_tfidf_mat)\n",
    "test_nmf_mat_50 = nmf.transform(test_tfidf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbea508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 5 ########################\n",
    "svm_soft_margin = svm.SVC(C=0.0001, kernel='linear', random_state=42)  # gamma=0.0001\n",
    "svm_hard_margin = svm.SVC(C=1000, kernel='linear', random_state=42)  # gamma=1000\n",
    "svm_harder_margin = svm.SVC(C=100000, kernel='linear', random_state=42)  # gamma=100000\n",
    "\n",
    "svm_soft_margin.fit(train_lsi_mat_50, label_train_gt)\n",
    "svm_hard_margin.fit(train_lsi_mat_50, label_train_gt)\n",
    "svm_harder_margin.fit(train_lsi_mat_50, label_train_gt)\n",
    "svm_soft_margin_predict = svm_soft_margin.predict(test_lsi_mat_50)\n",
    "svm_hard_margin_predict = svm_hard_margin.predict(test_lsi_mat_50)\n",
    "svm_harder_margin_predict = svm_harder_margin.predict(test_lsi_mat_50)\n",
    "\n",
    "print('Soft Margin SVM confusion matrix: ', confusion_matrix(label_test_gt, svm_soft_margin_predict))\n",
    "print('Soft Margin SVM accuracy score: ', accuracy_score(label_test_gt, svm_soft_margin_predict))\n",
    "print('Soft Margin SVM recall score: ', recall_score(label_test_gt, svm_soft_margin_predict))\n",
    "print('Soft Margin SVM precision score: ', precision_score(label_test_gt, svm_soft_margin_predict))\n",
    "print('Soft Margin SVM f1 score: ', f1_score(label_test_gt, svm_soft_margin_predict))\n",
    "print('Hard Margin SVM confusion matrix: ', confusion_matrix(label_test_gt, svm_hard_margin_predict))\n",
    "print('Hard Margin SVM accuracy score: ', accuracy_score(label_test_gt, svm_hard_margin_predict))\n",
    "print('Hard Margin SVM recall score: ', recall_score(label_test_gt, svm_hard_margin_predict))\n",
    "print('Hard Margin SVM precision score: ', precision_score(label_test_gt, svm_hard_margin_predict))\n",
    "print('Hard Margin SVM f1 score: ', f1_score(label_test_gt, svm_hard_margin_predict))\n",
    "print('Harder Margin SVM confusion matrix: ', confusion_matrix(label_test_gt, svm_harder_margin_predict))\n",
    "print('Harder Margin SVM accuracy score: ', accuracy_score(label_test_gt, svm_harder_margin_predict))\n",
    "print('Harder Margin SVM recall score: ', recall_score(label_test_gt, svm_harder_margin_predict))\n",
    "print('Harder Margin SVM precision score: ', precision_score(label_test_gt, svm_harder_margin_predict))\n",
    "print('Harder Margin SVM f1 score: ', f1_score(label_test_gt, svm_harder_margin_predict))\n",
    "\n",
    "def draw_roc_curve(fpr, tpr, model_name):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel(\"False Postive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Postive Rate (TPR)\")\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "fpr_soft, tpr_soft, _ = roc_curve(label_test_gt, svm_soft_margin.decision_function(test_lsi_mat_50))\n",
    "fpr_hard, tpr_hard, _ = roc_curve(label_test_gt, svm_hard_margin.decision_function(test_lsi_mat_50))\n",
    "fpr_harder, tpr_harder, _ = roc_curve(label_test_gt, svm_harder_margin.decision_function(test_lsi_mat_50))\n",
    "draw_roc_curve(fpr_soft, tpr_soft, 'Soft Margin SVM ROC Curve')\n",
    "draw_roc_curve(fpr_hard, tpr_hard, 'Hard Margin SVM ROC Curve')\n",
    "draw_roc_curve(fpr_harder, tpr_harder, 'Harder Margin SVM ROC Curve')\n",
    "\n",
    "# cross validation\n",
    "gamma = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "cv_scores = []\n",
    "for i in gamma:\n",
    "    svm_model = svm.SVC(C=i, kernel='linear', random_state=42)\n",
    "    score = cross_val_score(estimator=svm_model, X=train_lsi_mat_50, y=label_train_gt, cv=5)\n",
    "    cv_score = np.mean(score)\n",
    "    print(cv_score)\n",
    "    cv_scores.append(cv_score)\n",
    "print(cv_scores)\n",
    "best_score_index = cv_scores.index(max(cv_scores))\n",
    "best_gamma = gamma[best_score_index]\n",
    "print('best gamma:', best_gamma)  # best gamma = 10000 (notice: must keep the random_state of LSI as 0!)\n",
    "\n",
    "svm_best_margin = svm.SVC(C=best_gamma, kernel='linear', random_state=42)\n",
    "svm_best_margin.fit(train_lsi_mat_50, label_train_gt)\n",
    "svm_best_margin_predict = svm_best_margin.predict(test_lsi_mat_50)\n",
    "print('Best Margin SVM confusion matrix: ', confusion_matrix(label_test_gt, svm_best_margin_predict))\n",
    "print('Best Margin SVM accuracy score: ', accuracy_score(label_test_gt, svm_best_margin_predict))\n",
    "print('Best Margin SVM recall score: ', recall_score(label_test_gt, svm_best_margin_predict))\n",
    "print('Best Margin SVM precision score: ', precision_score(label_test_gt, svm_best_margin_predict))\n",
    "print('Best Margin SVM f1 score: ', f1_score(label_test_gt, svm_best_margin_predict))\n",
    "fpr_best, tpr_best, _ = roc_curve(label_test_gt, svm_best_margin.decision_function(test_lsi_mat_50))\n",
    "draw_roc_curve(fpr_best, tpr_best, 'Best Margin SVM ROC Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd49c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 6 ########################\n",
    "logistic_no_reg = LogisticRegression(penalty=None, solver='lbfgs', random_state=42)  # the logistic classifier without regularization\n",
    "logistic_no_reg.fit(train_lsi_mat_50, label_train_gt)\n",
    "logistic_no_reg_predict = logistic_no_reg.predict(test_lsi_mat_50)\n",
    "print('Logistic Classifier W/o Regularization confusion matrix: ', confusion_matrix(label_test_gt, logistic_no_reg_predict))\n",
    "print('Logistic Classifier W/o Regularization accuracy score: ', accuracy_score(label_test_gt, logistic_no_reg_predict))\n",
    "print('Logistic Classifier W/o Regularization recall score: ', recall_score(label_test_gt, logistic_no_reg_predict))\n",
    "print('Logistic Classifier W/o Regularization precision score: ', precision_score(label_test_gt, logistic_no_reg_predict))\n",
    "print('Logistic Classifier W/o Regularization f1 score: ', f1_score(label_test_gt, logistic_no_reg_predict))\n",
    "fpr_logistic_no_reg, tpr_logistic_no_reg, _ = roc_curve(label_test_gt, logistic_no_reg.decision_function(test_lsi_mat_50))\n",
    "draw_roc_curve(fpr_logistic_no_reg, tpr_logistic_no_reg, 'Logistic Classifier W/o Regularization ROC Curve')\n",
    "\n",
    "# cross validation for L1 regularization\n",
    "k = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10000, 100000]\n",
    "cv_scores = []\n",
    "for i in k:\n",
    "    logistic_l1_reg = LogisticRegression(penalty='l1', C=i, solver='liblinear', random_state=42)\n",
    "    score = cross_val_score(estimator=logistic_l1_reg, X=train_lsi_mat_50, y=label_train_gt, cv=5)\n",
    "    cv_score = np.mean(score)\n",
    "    print(cv_score)\n",
    "    cv_scores.append(cv_score)\n",
    "print(cv_scores)\n",
    "best_score_index = cv_scores.index(max(cv_scores))\n",
    "best_k = k[best_score_index]  # best k for L1 = 100\n",
    "print('best k for L1 regularization:', best_k)\n",
    "print('best regularization strength for L1 regularization:', 1/best_k)  # C is the inverse of regularization strength\n",
    "\n",
    "logistic_best_l1_reg = LogisticRegression(penalty='l1', C=best_k, solver='liblinear', random_state=42)\n",
    "logistic_best_l1_reg.fit(train_lsi_mat_50, label_train_gt)\n",
    "logistic_best_l1_reg_predict = logistic_best_l1_reg.predict(test_lsi_mat_50)\n",
    "print('Best L1 regularization confusion matrix: ', confusion_matrix(label_test_gt, logistic_best_l1_reg_predict))\n",
    "print('Best L1 regularization accuracy score: ', accuracy_score(label_test_gt, logistic_best_l1_reg_predict))\n",
    "print('Best L1 regularization recall score: ', recall_score(label_test_gt, logistic_best_l1_reg_predict))\n",
    "print('Best L1 regularization precision score: ', precision_score(label_test_gt, logistic_best_l1_reg_predict))\n",
    "print('Best L1 regularization f1 score: ', f1_score(label_test_gt, logistic_best_l1_reg_predict))\n",
    "\n",
    "# cross validation for L2 regularization\n",
    "k = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10000, 100000]\n",
    "cv_scores = []\n",
    "for i in k:\n",
    "    logistic_l2_reg = LogisticRegression(penalty='l2', C=i, solver='liblinear', random_state=42)\n",
    "    score = cross_val_score(estimator=logistic_l2_reg, X=train_lsi_mat_50, y=label_train_gt, cv=5)\n",
    "    cv_score = np.mean(score)\n",
    "    print(cv_score)\n",
    "    cv_scores.append(cv_score)\n",
    "print(cv_scores)\n",
    "best_score_index = cv_scores.index(max(cv_scores))\n",
    "best_k = k[best_score_index]\n",
    "print('best k for L2 regularization:', best_k)  # best k for L2 = 10000\n",
    "print('best regularization strength for L2 regularization:', 1/best_k)  # C is the inverse of regularization strength\n",
    "\n",
    "logistic_best_l2_reg = LogisticRegression(penalty='l2', C=best_k, solver='liblinear', random_state=42)\n",
    "logistic_best_l2_reg.fit(train_lsi_mat_50, label_train_gt)\n",
    "logistic_best_l2_reg_predict = logistic_best_l2_reg.predict(test_lsi_mat_50)\n",
    "print('Best L2 regularization confusion matrix: ', confusion_matrix(label_test_gt, logistic_best_l2_reg_predict))\n",
    "print('Best L2 regularization accuracy score: ', accuracy_score(label_test_gt, logistic_best_l2_reg_predict))\n",
    "print('Best L2 regularization recall score: ', recall_score(label_test_gt, logistic_best_l2_reg_predict))\n",
    "print('Best L2 regularization precision score: ', precision_score(label_test_gt, logistic_best_l2_reg_predict))\n",
    "print('Best L2 regularization f1 score: ', f1_score(label_test_gt, logistic_best_l2_reg_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb53089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 7 ########################\n",
    "gaussian_nb = GaussianNB()\n",
    "gaussian_nb.fit(train_lsi_mat_50, label_train_gt)\n",
    "gaussian_nb_predict = gaussian_nb.predict(test_lsi_mat_50)\n",
    "print('GaussianNB confusion matrix: ', confusion_matrix(label_test_gt, gaussian_nb_predict))\n",
    "print('GaussianNB accuracy score: ', accuracy_score(label_test_gt, gaussian_nb_predict))\n",
    "print('GaussianNB recall score: ', recall_score(label_test_gt, gaussian_nb_predict))\n",
    "print('GaussianNB precision score: ', precision_score(label_test_gt, gaussian_nb_predict))\n",
    "print('GaussianNB f1 score: ', f1_score(label_test_gt, gaussian_nb_predict))\n",
    "fpr_gaussian_nb, tpr_gaussian_nb, _ = roc_curve(label_test_gt, gaussian_nb.predict_proba(test_lsi_mat_50)[:, 1])\n",
    "draw_roc_curve(fpr_gaussian_nb, tpr_gaussian_nb, 'GaussianNB ROC Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 8 ########################\n",
    "def stem(text):  # stem the cleaned text\n",
    "    stemmer = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    result = []\n",
    "    for word in words:\n",
    "        result.append(stemmer.stem(word).lower())\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "train_stemmed_text = train_clean_text.apply(lambda x:stem(x))\n",
    "test_stemmed_text = test_clean_text.apply(lambda x:stem(x))\n",
    "print(train_stemmed_text)\n",
    "\n",
    "steps = [('convector', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()),\n",
    "         ('dim_reduce', TruncatedSVD(5, random_state=0)), ('classifier', svm.SVC(C=10000, kernel='linear', random_state=42))]\n",
    "pipeline = Pipeline(steps)\n",
    "param_dict = {\n",
    "    'convector__min_df': (3, 5),\n",
    "    'dim_reduce': (TruncatedSVD(5, random_state=0),\n",
    "                   TruncatedSVD(30, random_state=0),\n",
    "                   TruncatedSVD(80, random_state=0),\n",
    "                   NMF(n_components=5, random_state=0),\n",
    "                   NMF(n_components=30, random_state=0),\n",
    "                   NMF(n_components=80, random_state=0)),\n",
    "    'classifier': (svm.SVC(C=10000, kernel='linear', random_state=42),\n",
    "                   LogisticRegression(penalty='l1', C=100, solver='liblinear', random_state=42),\n",
    "                   LogisticRegression(penalty='l2', C=10000, solver='liblinear', random_state=42),\n",
    "                   GaussianNB())\n",
    "}\n",
    "\n",
    "# grid search for lemmatized data\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_dict, scoring='accuracy', cv=5, verbose=4)\n",
    "print('start grid search!!!')\n",
    "grid_search.fit(train_lemmatized_text, label_train_gt)\n",
    "print('Best estimator for lemmatization:', grid_search.best_estimator_)\n",
    "print('Best estimator\\'s parameters for lemmatization:', grid_search.best_params_)\n",
    "pd.DataFrame(grid_search.cv_results_).to_csv(path_or_buf=\"grid_results_lemma.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# grid search for stemmed data\n",
    "grid_search_2 = GridSearchCV(estimator=pipeline, param_grid=param_dict, scoring='accuracy', cv=5, verbose=4)\n",
    "print('start grid search!!!')\n",
    "grid_search_2.fit(train_stemmed_text, label_train_gt)\n",
    "print('Best estimator for stem:', grid_search_2.best_estimator_)\n",
    "print('Best estimator\\'s parameters for stem:', grid_search_2.best_params_)\n",
    "pd.DataFrame(grid_search_2.cv_results_).to_csv(path_or_buf=\"grid_results_stem.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# report the results of best 5 models\n",
    "steps_1 = [('convector', CountVectorizer(stop_words='english', min_df=3)), ('tfidf', TfidfTransformer()),\n",
    "           ('dim_reduce', TruncatedSVD(80, random_state=0)),\n",
    "           ('classifier', LogisticRegression(C=100, penalty='l1', random_state=42, solver='liblinear'))]\n",
    "pipeline_1 = Pipeline(steps_1)\n",
    "pipeline_1.fit(train_stemmed_text, label_train_gt)\n",
    "pipeline_1_predict = pipeline_1.predict(test_stemmed_text)\n",
    "print('Best 1 confusion matrix: ', confusion_matrix(label_test_gt, pipeline_1_predict))\n",
    "print('Best 1 accuracy score: ', accuracy_score(label_test_gt, pipeline_1_predict))\n",
    "print('Best 1 recall score: ', recall_score(label_test_gt, pipeline_1_predict))\n",
    "print('Best 1 precision score: ', precision_score(label_test_gt, pipeline_1_predict))\n",
    "print('Best 1 f1 score: ', f1_score(label_test_gt, pipeline_1_predict))\n",
    "\n",
    "steps_2 = [('convector', CountVectorizer(stop_words='english', min_df=5)), ('tfidf', TfidfTransformer()),\n",
    "           ('dim_reduce', TruncatedSVD(80, random_state=0)),\n",
    "           ('classifier', LogisticRegression(C=100, penalty='l1', random_state=42, solver='liblinear'))]\n",
    "pipeline_2 = Pipeline(steps_2)\n",
    "pipeline_2.fit(train_lemmatized_text, label_train_gt)\n",
    "pipeline_2_predict = pipeline_2.predict(test_lemmatized_text)\n",
    "print('Best 2 confusion matrix: ', confusion_matrix(label_test_gt, pipeline_2_predict))\n",
    "print('Best 2 accuracy score: ', accuracy_score(label_test_gt, pipeline_2_predict))\n",
    "print('Best 2 recall score: ', recall_score(label_test_gt, pipeline_2_predict))\n",
    "print('Best 2 precision score: ', precision_score(label_test_gt, pipeline_2_predict))\n",
    "print('Best 2 f1 score: ', f1_score(label_test_gt, pipeline_2_predict))\n",
    "\n",
    "steps_3 = [('convector', CountVectorizer(stop_words='english', min_df=3)), ('tfidf', TfidfTransformer()),\n",
    "           ('dim_reduce', NMF(80, random_state=0)),\n",
    "           ('classifier', LogisticRegression(C=100, penalty='l1', random_state=42, solver='liblinear'))]\n",
    "pipeline_3 = Pipeline(steps_3)\n",
    "pipeline_3.fit(train_stemmed_text, label_train_gt)\n",
    "pipeline_3_predict = pipeline_3.predict(test_stemmed_text)\n",
    "print('Best 3 confusion matrix: ', confusion_matrix(label_test_gt, pipeline_3_predict))\n",
    "print('Best 3 accuracy score: ', accuracy_score(label_test_gt, pipeline_3_predict))\n",
    "print('Best 3 recall score: ', recall_score(label_test_gt, pipeline_3_predict))\n",
    "print('Best 3 precision score: ', precision_score(label_test_gt, pipeline_3_predict))\n",
    "print('Best 3 f1 score: ', f1_score(label_test_gt, pipeline_3_predict))\n",
    "\n",
    "steps_4 = [('convector', CountVectorizer(stop_words='english', min_df=5)), ('tfidf', TfidfTransformer()),\n",
    "           ('dim_reduce', TruncatedSVD(80, random_state=0)),\n",
    "           ('classifier', LogisticRegression(C=10000, penalty='l2', random_state=42, solver='liblinear'))]\n",
    "pipeline_4 = Pipeline(steps_4)\n",
    "pipeline_4.fit(train_lemmatized_text, label_train_gt)\n",
    "pipeline_4_predict = pipeline_4.predict(test_lemmatized_text)\n",
    "print('Best 4 confusion matrix: ', confusion_matrix(label_test_gt, pipeline_4_predict))\n",
    "print('Best 4 accuracy score: ', accuracy_score(label_test_gt, pipeline_4_predict))\n",
    "print('Best 4 recall score: ', recall_score(label_test_gt, pipeline_4_predict))\n",
    "print('Best 4 precision score: ', precision_score(label_test_gt, pipeline_4_predict))\n",
    "print('Best 4 f1 score: ', f1_score(label_test_gt, pipeline_4_predict))\n",
    "\n",
    "steps_5 = [('convector', CountVectorizer(stop_words='english', min_df=3)), ('tfidf', TfidfTransformer()),\n",
    "           ('dim_reduce', TruncatedSVD(80, random_state=0)),\n",
    "           ('classifier', LogisticRegression(C=100, penalty='l1', random_state=42, solver='liblinear'))]\n",
    "pipeline_5 = Pipeline(steps_5)\n",
    "pipeline_5.fit(train_lemmatized_text, label_train_gt)\n",
    "pipeline_5_predict = pipeline_5.predict(test_lemmatized_text)\n",
    "print('Best 5 confusion matrix: ', confusion_matrix(label_test_gt, pipeline_5_predict))\n",
    "print('Best 5 accuracy score: ', accuracy_score(label_test_gt, pipeline_5_predict))\n",
    "print('Best 5 recall score: ', recall_score(label_test_gt, pipeline_5_predict))\n",
    "print('Best 5 precision score: ', precision_score(label_test_gt, pipeline_5_predict))\n",
    "print('Best 5 f1 score: ', f1_score(label_test_gt, pipeline_5_predict))\n",
    "\n",
    "#################### Question 9 ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 9 ########################\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "np.random.seed(42)  # make the training and testing samples the same as other groups\n",
    "random.seed(42)\n",
    "\n",
    "leaf_label = dataset[[\"leaf_label\"]]\n",
    "\n",
    "leaf_labels = ['chess', 'cricket', 'hockey', 'soccer', 'football', '%22forest%20fire%22', 'flood', 'earthquake', 'drought']\n",
    "\n",
    "leaf_train, leaf_test = train_test_split(dataset[[\"full_text\", \"leaf_label\"]], test_size=0.2)\n",
    "print('leaf_train.shape: ', leaf_train.shape)\n",
    "print('leaf_test.shape: ', leaf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_train_clean, leaf_test_clean = leaf_train.applymap(clean)['full_text'], leaf_test.applymap(clean)['full_text']\n",
    "leaf_train_lemma = leaf_train_clean.apply(lambda x: lemmatization(x))\n",
    "leaf_test_lemma = leaf_test_clean.apply(lambda x: lemmatization(x))\n",
    "leaf_train_count, leaf_test_count = cv.fit_transform(leaf_train_lemma), cv.transform(leaf_test_lemma)\n",
    "print('CountVectorizer transformation done')\n",
    "tfidf = TfidfTransformer()\n",
    "leaf_train_tfidf, leaf_test_tfidf = tfidf.fit_transform(leaf_train_count).toarray(), tfidf.transform(leaf_test_count).toarray()\n",
    "print('TFIDF transformation done')\n",
    "lsi = TruncatedSVD(n_components=50, random_state=42)\n",
    "nmf = NMF(n_components=50, random_state=42)\n",
    "leaf_train_lsi, leaf_test_lsi = lsi.fit_transform(leaf_train_tfidf), lsi.transform(leaf_test_tfidf)\n",
    "print('LSI transformation done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6dc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "def print_info(test, pred, title='', leaf_labels=leaf_labels):\n",
    "    cm = confusion_matrix(test, pred)\n",
    "    print(\"Confusion Matrix:\\n\")\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(test, pred, display_labels=np.array(leaf_labels), xticks_rotation='vertical')\n",
    "    disp.ax_.set_title(title)\n",
    "    plt.show()\n",
    "    print(\"Accuracy Score: \", accuracy_score(test, pred))\n",
    "    print(\"Recall Score: \", recall_score(test, pred, average='macro'))\n",
    "    print(\"Precision Score: \", precision_score(test, pred, average='macro'))\n",
    "    print(\"F1 Score: \", f1_score(test, pred, average='macro'))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_id(labels):\n",
    "    label_gt = []\n",
    "    for label in labels:\n",
    "        for j, _class in enumerate(leaf_labels):\n",
    "            if label == _class:\n",
    "                label_gt.append(j)\n",
    "                break\n",
    "    return np.array(label_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "gaussian_nb = GaussianNB()\n",
    "y_train, y_test = label_to_id(leaf_train['leaf_label']), label_to_id(leaf_test['leaf_label'])\n",
    "pred = gaussian_nb.fit(leaf_train_lsi, y_train).predict(leaf_test_lsi)\n",
    "print_info(y_test, pred, title='Naïve Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass SVM One vs One\n",
    "svm_vs_one = OneVsOneClassifier(svm.LinearSVC(random_state=42))\n",
    "pred = svm_vs_one.fit(leaf_train_lsi, y_train).predict(leaf_test_lsi)\n",
    "print_info(y_test, pred, title='One VS One')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6001a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass SVM One vs Rest\n",
    "svm_vs_rest = OneVsRestClassifier(svm.LinearSVC(class_weight='balanced', random_state=42))\n",
    "pred = svm_vs_rest.fit(leaf_train_lsi, y_train).predict(leaf_test_lsi)\n",
    "print_info(y_test, pred, title='One VS The Rest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_leaf_labels = ['chess', 'cricket', 'hockey', 'football', '%22forest%20fire%22', 'flood', 'earthquake', 'drought']\n",
    "\n",
    "def label_to_id(labels):\n",
    "    label_gt = []\n",
    "    for label in labels:\n",
    "        temp = label\n",
    "        if label == 'soccer':\n",
    "            label = 'football'\n",
    "        for j, _class in enumerate(new_leaf_labels):\n",
    "            if label == _class:\n",
    "                label_gt.append(j)\n",
    "                break\n",
    "        label = temp\n",
    "    return np.array(label_gt)\n",
    "\n",
    "y_train, y_test = label_to_id(leaf_train['leaf_label']), label_to_id(leaf_test['leaf_label'])\n",
    "\n",
    "print(\"One VS One\\n\")\n",
    "# Multiclass SVM One vs One\n",
    "svm_vs_one = OneVsOneClassifier(svm.LinearSVC(class_weight='balanced', random_state=42))\n",
    "pred = svm_vs_one.fit(leaf_train_lsi, y_train).predict(leaf_test_lsi)\n",
    "print_info(y_test, pred, title='One VS One', leaf_labels=new_leaf_labels)\n",
    "\n",
    "print(\"One VS Rest\\n\")\n",
    "# Multiclass SVM One vs Rest\n",
    "svm_vs_rest = OneVsRestClassifier(svm.LinearSVC(class_weight='balanced', random_state=42))\n",
    "pred = svm_vs_rest.fit(leaf_train_lsi, y_train).predict(leaf_test_lsi)\n",
    "print_info(y_test, pred, title='One VS The Rest', leaf_labels=new_leaf_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 11 #######################\n",
    "\n",
    "# Get GLoVE embeddings from specified dimension file\n",
    "def get_glove_embeddings(dimension):\n",
    "    embeddings_dict = {}\n",
    "    with open(\"glove.6B.\" + str(dimension) + \"d.txt\", 'r', encoding=\"utf-8\") as f: # if 'r' fails with unicode error, please use 'rb'\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "    return embeddings_dict\n",
    "\n",
    "# Clean, remove stopwords, and lemmatize the full text. We have already cleaned the data earlier.\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_glove_text(text):\n",
    "    text = text.lower()\n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    return ' '.join([word for word in words if word not in stop_words])\n",
    "\n",
    "# Get keywords column as an additional representation of the text\n",
    "train_keywords = train['keywords']\n",
    "test_keywords = test['keywords']\n",
    "\n",
    "train_clean_text = train_clean_text.apply(lambda x: clean_glove_text(x))\n",
    "train_lemmatized_text = train_clean_text.apply(lambda x: lemmatization(x))\n",
    "train_clean_keywords = train_keywords.apply(lambda x: clean_glove_text(x))\n",
    "train_lemmatized_keywords = train_clean_keywords.apply(lambda x: lemmatization(x))\n",
    "\n",
    "test_clean_text = test_clean_text.apply(lambda x: clean_glove_text(x))\n",
    "test_lemmatized_text = test_clean_text.apply(lambda x: lemmatization(x))\n",
    "test_clean_keywords = test_keywords.apply(lambda x: clean_glove_text(x))\n",
    "test_lemmatized_keywords = test_clean_keywords.apply(lambda x: lemmatization(x))\n",
    "\n",
    "# Use Glove embeddings to get a vector representing the document\n",
    "def get_glove_representation(text, embeddings_dict):\n",
    "    glove_words = []\n",
    "    for word in text.split():\n",
    "        try:\n",
    "            glove_word = embeddings_dict[word]\n",
    "            glove_words.append(glove_word)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    glove_words = np.array(glove_words)\n",
    "    return glove_words.mean(axis = 0) # average across all word embeddings in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1177c1",
   "metadata": {},
   "source": [
    "For 300-dimension embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c161f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = get_glove_embeddings(300)\n",
    "train_glove_text = train_lemmatized_text.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "train_glove_text_300 = train_glove_text.values.tolist()\n",
    "train_glove_keywords = train_lemmatized_keywords.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "train_glove_keywords_300 = train_glove_keywords.values.tolist()\n",
    "train_glove_300 = np.mean([train_glove_text_300, train_glove_keywords_300], axis = 0)\n",
    "\n",
    "test_glove_text = test_lemmatized_text.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "test_glove_text_300 = test_glove_text.values.tolist()\n",
    "test_glove_keywords = test_lemmatized_keywords.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "test_glove_keywords_300 = test_glove_keywords.values.tolist()\n",
    "test_glove_300 = np.mean([test_glove_text_300, test_glove_keywords_300], axis = 0)\n",
    "\n",
    "# Run SVC with cross-validation with different hyperparameters\n",
    "gamma = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]\n",
    "cv_scores = []\n",
    "\n",
    "for i in gamma:\n",
    "    svm_model = svm.SVC(C=i, kernel='linear', random_state=42)\n",
    "    score = cross_val_score(estimator=svm_model, X=train_glove_300, y=label_train_gt, cv=5)\n",
    "    cv_score = np.mean(score)\n",
    "    cv_scores.append(cv_score)\n",
    "\n",
    "print(cv_scores)\n",
    "best_score_index = cv_scores.index(max(cv_scores))\n",
    "best_gamma = gamma[best_score_index]\n",
    "print('best gamma:', best_gamma)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters\n",
    "svm_model = svm.SVC(C=best_gamma, kernel='linear', random_state=42)\n",
    "svm_model.fit(train_glove_300, label_train_gt)\n",
    "svm_model_predict = svm_model.predict(test_glove_300)\n",
    "accuracy_glove_300 = accuracy_score(label_test_gt, svm_model_predict)\n",
    "print_info(label_test_gt, svm_model_predict, leaf_labels=[\"climate\", \"sports\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a48a88",
   "metadata": {},
   "source": [
    "Testing number of dimensions in GLoVE-embeddings versus testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 12 #######################\n",
    "\n",
    "# Testing with different GLoVE embedding dimensions. We don't tune hyperparameters, and just use the best gamma from Q11.\n",
    "\n",
    "dimensions = [50, 100, 200]\n",
    "accuracies = []\n",
    "\n",
    "for dimension in dimensions:\n",
    "    embeddings_dict = get_glove_embeddings(dimension)\n",
    "    \n",
    "    train_glove_text = train_lemmatized_text.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "    glove_text = train_glove_text.values.tolist()\n",
    "    train_glove_keywords = train_lemmatized_keywords.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "    glove_keywords = train_glove_keywords.values.tolist()\n",
    "    train_glove = np.mean([glove_text, glove_keywords], axis = 0)\n",
    "\n",
    "    test_glove_text = test_lemmatized_text.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "    glove_text = test_glove_text.values.tolist()\n",
    "    test_glove_keywords = test_lemmatized_keywords.apply(lambda x: get_glove_representation(x, embeddings_dict))\n",
    "    glove_keywords = test_glove_keywords.values.tolist()\n",
    "    test_glove = np.mean([glove_text, glove_keywords], axis = 0)\n",
    "\n",
    "    # Evaluate the model with the best hyperparameters\n",
    "    svm_model = svm.SVC(C=best_gamma, kernel='linear', random_state=42)\n",
    "    svm_model.fit(train_glove, label_train_gt)\n",
    "    svm_model_predict = svm_model.predict(test_glove)\n",
    "    accuracy_glove = accuracy_score(label_test_gt, svm_model_predict)\n",
    "    accuracies.append(accuracy_glove)\n",
    "\n",
    "# Add original accuracy score\n",
    "dimensions.append(300)\n",
    "accuracies.append(accuracy_glove_300)\n",
    "\n",
    "# Plot accuracy versus dimension of GLoVE embeddings\n",
    "plt.plot(dimensions, accuracies)\n",
    "plt.xlabel('Dimension of Embeddings')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Dimension of GLoVE Embeddings vs. Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Question 13 #######################\n",
    "\n",
    "def create_umap_plot(x, y, title): # ref: https://umap-learn.readthedocs.io/en/latest/plotting.html\n",
    "    embeddings = umap.UMAP().fit(x)\n",
    "    categorical_labels = []\n",
    "\n",
    "    for i in y:\n",
    "        if i == 0:\n",
    "            categorical_labels.append(\"climate\")\n",
    "        else:\n",
    "            categorical_labels.append(\"sports\")\n",
    "\n",
    "    umap.plot.points(embeddings, labels=np.array(categorical_labels), theme='viridis')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Create UMAP plots for training and testing data with dimensions = 300\n",
    "create_umap_plot(train_glove_300, label_train_gt, \"GLoVE Embeddings for Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0883e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_umap_plot(test_glove_300, label_test_gt, \"GLoVE Embeddings for Testing Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929828dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UMAP plot for random vectors with dimensions = 300\n",
    "random_x = np.random.normal(0, 1, size=(len(train_glove_300), 300))\n",
    "normalized_x = random_x / np.linalg.norm(random_x)\n",
    "create_umap_plot(normalized_x, label_train_gt, \"Random Normalized Vectors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 [gyf_python3_10]",
   "language": "python",
   "name": "gyf_python3_10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "39987ca6966f75618382f2ae5b08a4b2a561e189ea1b593602189bb0fc50e1ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
